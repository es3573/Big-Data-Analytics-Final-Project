{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as sm\n",
    "import seaborn as sns; sns.set()\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LassoCV, LassoLarsCV, LassoLarsIC\n",
    "from sklearn import datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/Hangyu/Desktop/loan.csv\")     #change to your own path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "msno.matrix(df)  \n",
    "#The msno.matrix nullity matrix is a data-dense display which lets you quickly visually pick out patterns in data completion.\n",
    "#visualize the missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape   #dimension of our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loan_status.value_counts()   #what we want to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 1, pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1-1, \n",
    "#Since the data can be devided into 2 groups, with co-borrowers or without co-borrowers\n",
    "#application_typeï¼Œ Indicates whether the loan is an individual application or a joint application with two co-borrowers\n",
    "df.application_type.value_counts()   \n",
    "#only 511 has co-borrowers, so we drop all co-borrowers' information, and keep application_type(which can be a indicator for loan status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_df = df.drop(['annual_inc_joint','dti_joint','verification_status_joint','acc_now_delinq','tot_coll_amt','tot_cur_bal','open_acc_6m','open_il_6m','open_il_12m',\n",
    "                  'open_il_24m','mths_since_rcnt_il','total_bal_il','il_util','open_rv_12m','open_rv_24m','max_bal_bc','all_util',\n",
    "                  'total_rev_hi_lim','inq_fi','total_cu_tl','inq_last_12m'], axis=1)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "msno.matrix(new_df)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1-2. Check Missing Value\n",
    "missing_portion = new_df.isnull().sum()/len(new_df)    #calculate the portion of missing value\n",
    "print(missing_portion.sort_values(ascending=False))\n",
    "#Here,pick a value and drop the factors base on the missing portion\n",
    "#My initial thought was drop everything above the \"emp_title\" , but when I looked into the columns' description\n",
    "#Factors like mths_since_last_record is definitely related to loan status, so I have to look into these factors 1 by 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a. desc: Loan description provided by the borrower\n",
    "#can be dropped, texture data, and lots of missing value\n",
    "new_df_2 = new_df.drop(['desc'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b. mths_since_last_record: The number of months since the last public record.\n",
    "#c. mths_since_last_major_derog: Months since most recent 90-day or worse rating\n",
    "#d. mths_since_last_delinq: The number of months since the borrower's last delinquency.    \n",
    "#can not be dropped, I guess the missing values should be replaced with \"0\" ***need further verification***\n",
    "values = {'mths_since_last_record': 0, 'mths_since_last_major_derog': 0, 'mths_since_last_delinq': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_3 = new_df_2.fillna(value=values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#e. next_pymnt_d: Next scheduled payment date\n",
    "new_df_4 = new_df_3.drop(['next_pymnt_d'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1-3. Missing Value Continued.(replacing missing value)\n",
    "df_no_missing = new_df_4.dropna()    #\n",
    "%matplotlib inline\n",
    "msno.matrix(df_no_missing)   #looks perfect, no missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2-1. drop texture data, and unnecessary data\n",
    "#id: A unique LC assigned ID for the loan listing.\n",
    "#member_id: A unique LC assigned Id for the borrower member.\n",
    "#emp_title: The job title supplied by the Borrower when applying for the loan.*\n",
    "#url: URL for the LC page with listing data.\n",
    "#policy_code: \"publicly available policy_code=1, new products not publicly available policy_code=2\"\n",
    "df_no_missing_1 = df_no_missing.drop(['id','member_id','emp_title','url','policy_code'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3-1. Status\n",
    "df_status = df_no_missing_1\n",
    "status_replace = {\"loan_status\" : { 'Current':1,'Issued':1,'Fully Paid':1,'In Grace Period':0,\n",
    "                                   'Does not meet the credit policy. Status:Fully Paid':1,\n",
    "                                   'Does not meet the credit policy. Status:Charged Off':0,\n",
    "                                   'Default':0,\n",
    "                                   'Late (31-120 days)':0,'Late (16-30 days)':0,'Charged Off':0 }}\n",
    "                  #The Current is a great portion of the data, maybe we can do like this. \"Good debt\" vs \"Bad debt\"\n",
    "df_status =df_status.replace(status_replace)\n",
    "df_status.loan_status.value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = ('Good Debt','Bad Debt')  #change names for title, ylab!\n",
    "y_pos = np.arange(len(objects))\n",
    "performance = df_status.loan_status.value_counts() \n",
    " \n",
    "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.title('Loan Status')\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3-2. Term\n",
    "term_replace = {\"term\" : { ' 36 months':0,' 60 months':1 }}\n",
    "df_term =df_status.replace(term_replace)\n",
    "df_term.term.value_counts() \n",
    "\n",
    "objects = term_replace['term']\n",
    "y_pos = np.arange(len(objects))\n",
    "performance = df_term.term.value_counts() \n",
    " \n",
    "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.title('term')\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3-3. Grade & Sub_grade\n",
    "grade_replace = {\"grade\" : {'A':0,'B':1,'C':2,'D':3,'E':4,'F':5,'G':6 }}\n",
    "df_grade =df_term.replace(grade_replace)\n",
    "df_grade.grade.value_counts() \n",
    "\n",
    "sub_grade_replace = {\"sub_grade\" :{'A1':0, 'A2':1, 'A3':2, 'A4':3, 'A5':4,\n",
    "                                   'B1':5, 'B2':6, 'B3':7, 'B4':8, 'B5':9,\n",
    "                                   'C1':10,'C2':11,'C3':12,'C4':13,'C5':14,\n",
    "                                   'D1':15,'D2':16,'D3':17,'D4':18,'D5':19,\n",
    "                                   'E1':20,'E2':21,'E3':22,'E4':23,'E5':24,\n",
    "                                   'F1':25,'F2':26,'F3':27,'F4':28,'F5':29,\n",
    "                                   'G1':30,'G2':31,'G3':32,'G4':33,'G5':34\n",
    "                                  }}\n",
    "df_sub_grade =df_grade.replace(sub_grade_replace)\n",
    "labels = 'A','B','C','D','E','F','G'\n",
    "sizes = df_sub_grade.grade.value_counts()\n",
    "colors = ['b','g','r','c','m','y','w']\n",
    "plt.pie(sizes,colors=colors,labels=labels)\n",
    "plt.axis('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = \"B\",\"C\",\"A\",\"D\",\"E\",\"F\",\"G\"\n",
    "y_pos = np.arange(len(objects))\n",
    "performance = df_sub_grade.grade.value_counts() \n",
    " \n",
    "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.title('grade')\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub_grade.grade.value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3-3. emp_length\n",
    "emp_length_replace = { \"emp_length\": {\"10+ years\": 10,\"2 years\": 2, \"< 1 year\": 0,\n",
    "                                      \"3 years\": 3, \"1 year\": 1,\"5 years\": 5,\n",
    "                                      \"4 years\": 4, \"7 years\": 7,\"8 years\": 8,\n",
    "                                       \"6 years\": 6, \"9 years\": 9,\n",
    "                                      }}\n",
    "df_emp_length =df_sub_grade.replace(emp_length_replace)\n",
    "df_emp_length.emp_length.value_counts()\n",
    "\n",
    "objects = emp_length_replace['emp_length']\n",
    "y_pos = np.arange(len(objects))\n",
    "performance = df_emp_length.emp_length.value_counts() \n",
    "\n",
    "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects,rotation='vertical')\n",
    "plt.title('emp_length')\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3-4. home ownership\n",
    "home_ownership_replace = { \"home_ownership\": {'MORTGAGE':2,'RENT':1,'OWN':0,'OTHER':3,'NONE':3,'ANY':3}}\n",
    "df_home_ownership =df_emp_length.replace(home_ownership_replace)\n",
    "\n",
    "objects = \"MORTGAGE\",\"RENT\",\"OWN\",\"OTHER\"\n",
    "y_pos = np.arange(len(objects))\n",
    "performance = df_home_ownership.home_ownership.value_counts() \n",
    " \n",
    "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.title('home ownership')\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3-4. verification_status\n",
    "verification_status_replace = { \"verification_status\": {'Not Verified':0,'Source Verified':1,'Verified':1}}\n",
    "df_verification_status =df_home_ownership.replace(verification_status_replace)\n",
    "\n",
    "objects = \"Verified\",\"Not Verified\"\n",
    "y_pos = np.arange(len(objects))\n",
    "performance = df_verification_status.verification_status.value_counts() \n",
    " \n",
    "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.title('Income Source Verified Status')\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3-5. issue_d\n",
    "df_issue_d = df_verification_status.drop(['issue_d'], axis=1)  #drop the issue_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3-6. pymnt_plan\n",
    "df_pymnt_plan = df_issue_d.drop(['pymnt_plan'], axis=1)  #drop the pymnt_plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3-7. purpose \n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df_pymnt_plan['purpose'])\n",
    "df_pymnt_plan['purpose']=le.transform(df_pymnt_plan['purpose'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3-8.title\n",
    "df_title = df_pymnt_plan.drop(['title'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3-8.zip code\n",
    "df_zip_code = df_title.drop(['zip_code'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3-9. addr_state \n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df_zip_code['addr_state'])\n",
    "df_zip_code['addr_state']=le.transform(df_zip_code['addr_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3-10. earliest_cr_line\n",
    "df_zip_code['earliest_cr_line']=df_zip_code['earliest_cr_line'].str.extract(r'(\\d+)')\n",
    "df_zip_code.earliest_cr_line.value_counts()\n",
    "df_zip_code.loc[df_zip_code.earliest_cr_line.astype('int') < 1977, 'earliest_cr_line'] = 'earlier than 1977' \n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df_zip_code['earliest_cr_line'])\n",
    "df_zip_code['earliest_cr_line']=le.transform(df_zip_code['earliest_cr_line'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3-10. initial_list_status\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df_zip_code['initial_list_status'])\n",
    "df_zip_code['initial_list_status']=le.transform(df_zip_code['initial_list_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3-11. last_pymnt_d                  \n",
    "df_last_pymnt_d = df_zip_code.drop(['last_pymnt_d'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3-12. last_credit_pull_d                            \n",
    "df_last_credit_pull_d = df_last_pymnt_d.drop(['last_credit_pull_d'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3-13. application_type\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df_last_credit_pull_d['application_type'])\n",
    "df_last_credit_pull_d['application_type']=le.transform(df_last_credit_pull_d['application_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_last_credit_pull_d.to_csv('Preprocessed_Pre_VIF.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor    \n",
    "\n",
    "def calculate_vif_(X, thresh=5.0):\n",
    "    variables = list(range(X.shape[1]))\n",
    "    dropped = True\n",
    "    while dropped:\n",
    "        dropped = False\n",
    "        vif = [variance_inflation_factor(X.iloc[:, variables].values, ix)\n",
    "               for ix in range(X.iloc[:, variables].shape[1])]\n",
    "\n",
    "        maxloc = vif.index(max(vif))\n",
    "        if max(vif) > thresh:\n",
    "            print('dropping \\'' + X.iloc[:, variables].columns[maxloc] +\n",
    "                  '\\' at index: ' + str(maxloc))\n",
    "            del variables[maxloc]\n",
    "            dropped = True\n",
    "    print(vif)\n",
    "    print('Remaining variables:')\n",
    "    print(X.columns[variables])\n",
    "    return X.iloc[:, variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Pre_Vif = df_last_credit_pull_d.loc[:, df_last_credit_pull_d.columns != 'loan_status']\n",
    "calculate_vif_(df_Pre_Vif,5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Preprocessed_data_VIF = df_last_credit_pull_d.drop(['total_pymnt','out_prncp_inv','funded_amnt',\n",
    "                                         'funded_amnt_inv','total_pymnt_inv','loan_amnt',\n",
    "                                         'sub_grade','int_rate','installment','open_acc',\n",
    "                                         'total_rec_prncp','earliest_cr_line','dti','revol_util',\n",
    "                                         'total_acc'], axis=1) \n",
    "Preprocessed_data_VIF.to_csv('Preprocessed_Pre_GLM.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Preprocessed_data_Heatmap = pd.read_csv(\"C:/Users/Hangyu/Desktop/R_Output.csv\")     #change to your own path\n",
    "col_filter = list(Preprocessed_data_Heatmap.columns.values)[1:]\n",
    "colormap = plt.cm.inferno\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.title('Pearson Correlation of Features', y=1.05, size=15)\n",
    "sns.heatmap(Preprocessed_data_Heatmap[col_filter].corr(),linewidths=0.1,vmax=1.0, square=True, cmap=colormap, linecolor='white', annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Data = Preprocessed_data_Heatmap.drop(['mths_since_last_delinq','mths_since_last_record'], axis=1) \n",
    "col_filter = list(Final_Data.columns.values)[1:]\n",
    "colormap = plt.cm.inferno\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.title('Pearson Correlation of Features', y=1.05, size=15)\n",
    "sns.heatmap(Final_Data[col_filter].corr(),linewidths=0.1,vmax=1.0, square=True, cmap=colormap, linecolor='white', annot=True)\n",
    "Final_Data.to_csv('Final_Data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
